# HOFNet

This package provides a multi-scale learning model for hydrogen-bonded organic framework (HOF) materials, called HOFNet. The model employs a multimodal materials transformer architecture, specifically designed for HOF materials, by incorporating three pretraining tasks that are better suited for HOFs: Pore Volume Fraction Prediction (VFP), Hydrogen Bond Position Prediction (HBP), and Molecular Fingerprint Prediction (FPP). These tasks allow HOFNet to learn structural information about HOFs at different scales. The model has achieved outstanding performance on the solvent property prediction task for HOFs using a small dataset of HOFs. HOFNet, pre-trained on 621 real HOF samples (or augmented with synthetic HOF data generated by HOFDiff), outperforms all current materials pretraining models in downstream solvent-type prediction tasks.

## Installation

Note: This package has been primarily tested on Linux. We strongly recommend using Linux for installation.

> ```python
> python>=3.8
> ```

Since MOFTransformer is based on PyTorch, please install PyTorch (>= 1.12.0) according to your environment.

### Installation via pip

```bash
$ pip install hofnet
```

## Getting Started

### Data Preprocessing

```python
from hofnet.examples import example_path
from hofnet.utils import prepare_data

# Example paths for CIFs and dataset
root_cifs = "/data/user2/wty/HOF/MOFDiff/tobacco_cif"
root_dataset = "/data/user2/wty/HOF/MOFDiff/tobacco_cif"

# Run data preparation
prepare_data(root_cifs, root_dataset, downstream=None)
```

### Calculating Molecular Fingerprints, HOF Pore Volume Fraction (VFP), and Hydrogen Bonds

```bash
# Calculate molecular fingerprints using cal_fp.py:
python your_script.py --input_file "./data/real_hofs.json" --output_file "./data/all_fp.json" --files_path "./data/total" --timeout 10

# Calculate hydrogen bonds using cal_hbond.py:
python your_script.py --cifs_path "./hof_database_cifs" --output_json_path "./hof_hbond_data.json"

# Calculate pore volume fraction using cal_vfp.py:
python process_cif.py --json_path "./data/real_hofs.json" --output_json_path "./data/real_hofs_vfp.json" --ZEO_PATH "./zeo++-0.3/network" --cif_dir "./data/total" --radius "0.5" --num_sample "50000" --max_workers 8
```

In this project, molecular fingerprints, hydrogen bond positions, and pore volume fractions for the training, validation, and test sets have already been computed and saved in `/data/HOF_{}/fold{}` directories.

### Pretraining

```python
import hofnet
from pathlib import Path
import torch
import torch.nn as nn
import torch.optim as optim
import os
from torch.utils.tensorboard import SummaryWriter
import numpy as np
from pathlib import Path
import hofnet
from hofnet.examples import example_path
import pandas as pd
from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score
import seaborn as sns
import matplotlib.pyplot as plt
import json

# Data root and downstream from example
fold = 'fold5'
devices = [0,1,2,3]
max_epochs = 2000
batch_size = 8
root_dataset = f'/mnt/user2/wty/HOF/moftransformer/data/HOF_pretrain_new/{fold}'
cifs_path = '/mnt/user2/wty/HOF/MOFDiff/mofdiff/data/mof_models/mof_models/bwdb_hoff/hofchecker_1/total'
fp_file_path = '/mnt/user2/wty/HOF/moftransformer/data/HOF_pretrain_new/all_fp.json'
task = 'vfp'
downstream = task

log_dir = f'/mnt/user2/wty/HOF/logs/HOF_pretrain/{fold}'
load_path = None
# load_path = 'pmtransformer'
os.makedirs(log_dir, exist_ok=True)

hofnet.run(root_dataset, downstream, log_dir=log_dir,                   
                max_epochs=max_epochs, batch_size=batch_size, devices=devices, loss_names=['hbond', 'fp', 'vfp'],
                cifs_path=cifs_path, fold=fold, fp_file_path=fp_file_path,
                load_path=load_path, learning_rate=1e-5)
```

### Fine-Tuning

```python
# train.py

import os
from pathlib import Path
import hofnet
import torch
from hofnet.run import run

# Configuration and paths
fold = 'fold5'
devices = [1]
max_epochs = 200
batch_size = 32
seed = 0               # default seeds
BASE_DATA = './data'
BASE_LOG = './logs'
root_dataset = f'{BASE_DATA}/HOF_solvent/fold{fold}'
task = 'solvent'
downstream = task
log_dir = f'{BASE_LOG}/solvent/fold{fold}'
os.makedirs(log_dir, exist_ok=True)
cifs_path = './data/total'
load_path = './logs/HOF_pretrain/fold5/pretrained_mof_seed0_from_/version_2/checkpoints/best.ckpt'  # Pretrained model path

# Get latest version of checkpoint
def get_latest_version(log_dir, seed):
    base_path = Path(log_dir) / f'pretrained_mof_seed{seed}_from_{pretrain_model}'
    os.makedirs(base_path, exist_ok=True)
    version_dirs = [d for d in base_path.iterdir() if d.is_dir() and d.name.startswith('version_')]
    if not version_dirs:
        return -1
    
    latest_version = max(int(d.name.split('_')[1]) for d in version_dirs)
    return latest_version

pretrain_model = load_path.split('/')[-1].split('.')[0] if load_path is not None else ''
version = get_latest_version(log_dir, seed) + 1
print("version:", version)

# Run pretraining
hofnet.run(
    root_dataset, downstream, log_dir=log_dir,                   
    max_epochs=max_epochs, batch_size=batch_size, devices=devices, 
    cifs_path=cifs_path, loss_names="solvent_classification", num_workers=4, 
    load_path=load_path, freeze_layers=False
)
```

### Testing

```python
# test.py

import os
from pathlib import Path
import hofnet
import pandas as pd
import numpy as np
import ast
from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score
from sklearn.preprocessing import LabelBinarizer

# Paths and configurations
BASE_LOG = './logs'
task = 'solvent'
fold = 'fold5'
pretrain_model = 'pretrained_mof_seed0_from_'
version = 3  # Example: the latest version to be tested
log_dir = f'{BASE_LOG}/{task}/fold{fold}/pretrained_mof_seed0_from_{pretrain_model}'
save_dir = Path(log_dir) / f'pretrained_mof_seed0_from_{pretrain_model}/version_{version}'

# Load data
solvents_df = pd.read_csv('/mnt/user2/wty/HOF/solvent.csv')
results_df = pd.read_csv(Path(save_dir) / f'updated_classification_results.csv')

# Define a function for MSE calculation
def mse(y_true, y_pred):
    return np.mean((np.array(y_true) - np.array(y_pred))**2)

# Preprocess results
results_df['solvent_classification_logits'] = results_df['solvent_classification_logits'].apply(ast.literal_eval)
results_df['solvent_classification_labels'] = results_df['solvent_classification_labels'].apply(ast.literal_eval)
results_df['top1_solvent'] = ""
results_df['top2_solvent'] = ""
results_df['top3_solvent'] = ""

# Merge solvent properties
solvents_df['properties'] = solvents_df[['LogP', 'Area', 'donors', 'acceptors', 'point']].values.tolist()

# Calculate the closest solvents
for index, row in results_df.iterrows():
    mse_scores = solvents_df['properties'].apply(lambda x: mse(x, row['solvent_classification_logits']))
    closest_solvents = mse_scores.nsmallest(3).index
    results_df.at[index, 'top1_solvent'] = solvents_df.at[closest_solvents[0], 'solvent1_label']
    results_df.at[index, 'top2_solvent'] = solvents_df.at[closest_solvents[1], 'solvent1_label']
    results_df.at[index, 'top3_solvent'] = solvents_df.at[closest_solvents[2], 'solvent1_label']

    mse_scores_true = solvents_df['properties'].apply(lambda x: mse(x, row['solvent_classification_labels']))
    closest_true_solvent = mse_scores_true.idxmin()
    results_df.at[index, 'true_solvent'] = solvents_df.at[closest_true_solvent, 'solvent1_label']

# Save updated results
results_df.to_csv(Path(save_dir) / f'updated_classification_results.csv', index=False)

# Evaluate predictions
df = pd.read_csv(Path(save_dir) / f'updated_classification_results.csv')

def evaluate_predictions(true_labels, predictions, average_type='macro'):
    accuracy = accuracy_score(true_labels, predictions)
    precision = precision_score(true_labels, predictions, average=average_type, zero_division=0)
    recall = recall_score(true_labels, predictions, average=average_type, zero_division=0)
    f1 = f1_score(true_labels, predictions, average=average_type, zero_division=0)
    return accuracy, precision, recall, f1

top1_accuracy, top1_precision, top1_recall, top1_f1 = evaluate_predictions(df['true_solvent'], df['top1_solvent'])

# Top2 and Top3 accuracy calculation
def multi_top_accuracy(true_labels, predictions):
    correct = 0
    for i in range(len(true_labels)):
        if true_labels[i] in predictions[i]:
            correct += 1
    return correct / len(true_labels)

top2_preds = df[['top1_solvent', 'top2_solvent']].values.tolist()
top3_preds = df[['top1_solvent', 'top2_solvent', 'top3_solvent']].values.tolist()

top2_accuracy = multi_top_accuracy(df['true_solvent'], top2_preds)
top3_accuracy = multi_top_accuracy(df['true_solvent'], top3_preds)

print(f"Top1 Accuracy: {top1_accuracy}, Precision: {top1_precision}, Recall: {top1_recall}, F1: {top1_f1}")
print(f"Top2 Accuracy: {top2_accuracy}")
print(f"Top3 Accuracy: {top3_accuracy}")
```

